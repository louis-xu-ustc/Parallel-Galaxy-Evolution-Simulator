<section class="main-content">
    <h2>
        <a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span
                class="octicon octicon-link"></span></a><b>Project Checkpoint</b></h2>

    <h4> Make sure your project schedule on your main project page is up to date with work completed so far, and well as
        with a revised plan of work for the coming weeks. As by this time you should have a good understanding of what
        is required to complete your project, I want to see a very detailed schedule for the coming weeks. I suggest
        breaking time down into half-week increments. Each increment should have at least one task, and for each task
        put a person's name on it.
    </h4>

    <ul>
        <p>
            Our time schedule table has been updated accordingly.
        <table class="pure-table pure-table-horizontal">
            <thead>
            <tr bgcolor="#f0f0f0">
                <th>#</th>
                <th>Date</th>
                <th>Goals</th>
                <th>Status</th>
            </tr>
            </thead>

            <tbody>
            <tr>
                <td>1</td>
                <td nowrap="nowrap">4.10 - 4.16</td>
                <td>Read papers on possible optimizations on N-body simulation problem (team)
                </td>
                <td>&#10003;</td>
            </tr>

            <tr bgcolor="#f0f0f0">
                <td>2</td>
                <td nowrap="nowrap">4.17 - 4.23</td>
                <td>Refine the starter sequential implementation of the Barnes-Hut algorithm (team)</td>
                <td>&#10003;</td>
            </tr>

            <tr>
                <td>3</td>
                <td nowrap="nowrap">4.17 - 4.23</td>
                <td>Complete unoptimized parallel implementation of the Barnes-Hut algorithm (Zhikun Lao);</br>
                    Complete Morton code based N-tree construction (Yunpeng Xu)
                </td>
                <td>&#10003;</td>
            </tr>

            <tr bgcolor="#f0f0f0">
                <td>4</td>
                <td nowrap="nowrap">4.23 - 4.24</td>
                <td>Complete project checkpoint report (team)</td>
                <td>&#10003;</td>
            </tr>

            <tr>
                <td>5</td>
                <td nowrap="nowrap">4.25 - 4.27</td>
                <td>Complete the optimized version of parallel implementation of the Barnes-Hut algorithm;</br>
                    Complete the cuda version of the Morton code based simulation
                </td>
                <td></td>
            </tr>

            <tr bgcolor="#f0f0f0">
                <td>6</td>
                <td nowrap="nowrap">4.28 - 5.1</td>
                <td>Complete the sequential implementation of the Fast Multipole Method</td>
                <td></td>
            </tr>

            <tr>
                <td>7</td>
                <td nowrap="nowrap">5.2 - 5.5</td>
                <td>Complete the cuda implementation of the Fast Multipole Method</td>
                <td>
                </td>
            </tr>
            <tr bgcolor="#f0f0f0">
                <td>8</td>
                <td nowrap="nowrap">5.2 - 5.5</td>
                <td>Finish any good-to-have features</td>
                <td></td>
            </tr>
            <tr>
                <td>9</td>
                <td nowrap="nowrap">5.6 - 5.10</td>
                <td>Draft final report and complete project pages</td>
                <td>
                </td>
            </tr>
            </tbody>
        </table>
        </p>
    </ul>

    <h4> One to two paragraphs, summarize the work that you have completed so far. (This should be easy if you have been
        maintaining this information on your project page.)
    </h4>

    <ul>
        <p>
            Firstly, we refactor our starter code to using c++. The reason is that we will have to use CUDA and CUDA
            doesn't have C binding. The refactored code is now structured oriented several classes: SpaceController,
            SpaceModel, and SpaceView. Although they sound like the three components of MVC, they are actually not. The
            SpaceController is responsible for generating random particles and passing the same set of particles to
            different SpaceModels. SpaceModel is responsible for actually do the simulation of the particles, that is,
            generating a quadtree from the location information of the particles, calculating the forces on each
            particle, and etc. Different simulation methods (e.g. sequential Barnes Hut, parallel Barnes Hut) take the
            form of subclasses of SpaceModel (e.g. seqBHSpaceModel). SpaceView is responsible for calling into the GLFW
            library and rendering the images of particles on the screen.
        </p>
        <p>
            Secondly, we implemented the unoptimized CUDA Barnes Hut algorithm. It is based on the simulation method
            introduced by Martin Burtscher and Keshav Pingali. In this solution, one simulation timestep can be divided
            into several kernels, with each kernel responsible for one single task (e.g. building the array-based
            quadtree on GPU, calculating the forces on each particle parallelly). However, the current implementation
            suffers from too much overhead of data transfer between host and device(GPU). Also, to guarantee the
            authenticity of our final project, a <a href="http://ieeexplore.ieee.org/document/7097874/?reload=true">new
            force calculation
            method</a> will be implemented.
        </p>

        <p>
            Thirdly, we implemented another algorithm that can parallel the tree construction process based on the
            Morton
            code. <a herf="http://www.sciencedirect.com/science/article/pii/S0021999111007364">The reference can be
            found here.</a> In this algorithm, the Morton code will be generated according to the position of the
            particle.
            The Morton code is then used with the level mask together to help group those particles into a cell. A cell
            can be seen as a representative of these particles including their weighted position and mass. It will help
            reduce the calculation compared to the brute force and BarnesHut method, and do the tree construction in a
            parallel way. The limitation is that when the number of particles increases to a large number (let's say 1
            million), it will become difficult to do the hashing using Morton code, since the number of particles that
            will be grouped into the same cell increases and decreases the precision of the calculation.
        </p>
    </ul>

    <h4>
        Describe how you are doing with respect to the goals and deliverables stated in your proposal. Do you still
        believe you will be able to produce all your deliverables? If not, why? What about the "nice to haves"? In your
        checkpoint writeup we want a new list of goals that you plan to hit for the Parallelism competition.
    </h4>

    <ul>
        <p>
            Shortly speaking, we changed our plan slightly so one milestone was missed (the sequential FMM method
            milestone) and we will have to put more effort on the final project in order to keep our project on track.
            We made a decision that before implementing the sequential FMM method, we would first try to implement
            another solution (the Morton code based N-tree construction). However, given that we have become familiar
            with the project and have gained enough domain knowledge, we think we will be able to speed up the
            implementation process and complete the parts of FMM methods. We will try our best to achieve any "nice to
            haves". To be realistic, as can be seen in the updated time schedule table, we won't have much time for
            "nice to haves".</br>
            <strong>TODO</strong>: needs some more discussions on a new list of goals that you plan to hit for the
            Parallelism competition.
        </p>
    </ul>

    <h4>
        What do you plan to show at the parallelism competition? Will it be a demo? Will it be a graph?
    </h4>
    <ul>
        <p>
            we plan to show a video that records the beautiful pattern of the galaxy evolution simulator
            and several graphs that compare the performance of different algorithms. Currently, we intend to include
            sequential BarnesHut, sequential MortonCode, parallel BarnesHut and parallel MortonCode. If time permits,
            we also wants to try Fast Multipole Method (FMM) mentioned in the proposal.
        </p>
    </ul>

    <h4>
        Do you have preliminary results at this time? If so, it would be great to included them in your checkpoint
        write-up.
    </h4>
    <ul>
        <div align="center">
            <img style='height: 80%; width: 80%; object-fit: contain' src="img/simulator_without_bouds.jpg"/><br/> <br/>
            <strong>Figure 1. sequential Barnus-Hut without bounds</strong>
        </div>
        <p>
            <strong>Figure 1</strong> depicts the spiral pattern of galaxy evolution using sequential Barnus-Hut method.
        </p>
        <div align="center">
            <img style='height: 80%; width: 80%; object-fit: contain' src="img/simulator_with_bouds.jpg"/><br/> <br/>
            <strong>Figure 2. sequential Barnus-Hut with bounds</strong>
        </div>
        <p>
            <strong>Figure 2</strong> depicts the spiral pattern of galaxy evolution using sequential Barnus-Hut method
            and also the
            bounds of quad-tree in that iteration during the simulation period.
        </p>
        <div align="center">
            <img src="img/curr_perf_comp.png"/><br/> <br/>
            <strong>Figure 3. current performance comparison result</strong>
        </div>
        <p>
            <strong>Figure 3</strong> is a screen shot that depicts the current performance comparison result. As you
            can see, we have finished three versions of galaxy simulator - seqBarnes, seqMorton and cudaBarnes.
            We do some simple statistic analysis about the result, including total time consumption to generate the
            pattern in 1000 loops, and the average time consumption for a single loop. It's clear that both the total
            time
            and average time consumption decrease sharply from seqBarnes to cudaBarnes.
        </p>
    </ul>

    <h4>
        List the issues that concern you the most. Are there any remaining unknowns (things you simply don't know how to
        solve, or resource you don't know how to get) or is it just a matter of coding and doing the work? If you do not
        wish to put this information on a public web site you are welcome to email the staff directly.
    </h4>
    <ul>
        <li>
            the first concern is that we need to figure out a better method to evaluate the performance of different
            algorithms, since different algorithms use different strategies to grouping particles. We cannot directly
            say one algorithm is better than the other one, even between sequential and parallel versions. One
            method may have an approximation ratio (let's say 5%) to the result of sequential Barnus-Hut version for
            every
            frame.
        </li>
        <li>
            according to our original plan, the second algorithm to implement is Fast Multipole Method (FMM), but later
            during in the reference survey, we find an algorithm that uses Morton code to approximately group particles
            and also supports parallel constructing the tree which is the bottleneck of the previous sequential
            Barnes-Hut version. Currently, we delay the implementation of FMM algorithm and will do the parallel
            version for this new Morton code based method first. So, FMM becomes one of the remaining unknowns. We may
            put this feature into "nice to have" list.
        </li>
    </ul>

    <h3>
        <a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span
                class="octicon octicon-link"></span></a>References<a name="ref"></a></h3>
    <ol type="1">
        <li><a href="http://www.sciencedirect.com/science/article/pii/S0021999111007364">Bedorf, Jeroen, Evghenii
            Gaburov, and Simon Portegies Zwart. "A sparse octree gravitational N-body code that
            runs entirely on the GPU processor." Journal of Computational Physics 231.7 (2012): 2825-2839. </a>
        </li>
    </ol>

    <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/louis-xu-ustc/Parallel-Galaxy-Evolution-Simulator">
            Parallel Galaxy Evolution Simulator</a> is maintained by <a href="https://github.com/louis-xu-ustc">louis-xu-ustc</a>.
        </span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a
                href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a
                href="https://twitter.com/jasonlong">Jason Long</a>.
        </span>
    </footer>

</section>
